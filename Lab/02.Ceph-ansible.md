# Triển khai Cluster Ceph sử dụng Ceph-ansible

## 1. Chuẩn bị
### 1.1 Clone repo git
```
git clone https://github.com/ceph/ceph-ansible.git
cd ceph-ansible
git checkout stable-4.0
```
### 1.2. Cài các thư viện Python libraries cần thiết:
```sh
pip install -r requirements.txt
```
## 2. Thực hiện 1 số bài LAB
### 2.1 Cài đặt Cluster Ceph
- Copy ssh-key sang các Node Ceph
```sh
ssh-copy-id mon1
ssh-copy-id mon2
ssh-copy-id mon3
ssh-copy-id osd1
ssh-copy-id osd2
ssh-copy-id osd3
```
- Tạo file `inventory` khai báo các Node Ceph
```sh
cat << EOF >> inventory
[mons]
mon1
mon2
mon3

[mgrs]
mon1
mon2
mon3

[osds]
osd1
osd2
osd3

[grafana-server]
mon01
EOF
```
- Tạo `playbook` sử dụng sample sẵn có
```sh
cp site.yml.sample playbook-ceph.yml
```
- Khai báp `group_vars`
Chỉnh sử file `all.yml` với nội dung sau:
```sh
ceph_origin: repository
ceph_repository: community
ceph_stable_release: nautilus
public_network: "192.168.1.0/24"
cluster_network: "172.16.1.0/24"
monitor_interface: eth0
devices:
  - '/dev/sda'
  - '/dev/sdb'
```
- Khởi tạo Cluster Ceph
```sh
cd ansible-ceph
ansible-playbook playbook-ceph.yml -i inventory
```
### 2.2 Thêm OSD vào Cluster

Để thêm Node OSD vào CLuster, thực hiện khai báo file `inventory` thêm Node mới và comment các Node đã Deploy tương tự như sau:
```sh
vim ceph-ansible/inventory
[mons]
mon1
mon2
mon3

[mgrs]
mon1
mon2
mon3

[osds]
# Comment các Node đã deploy 
#osd1
#osd2
#osd3
# Thêm Node OSD tại đây
osd4

[grafana-server]
mon01
EOF
```
- Chỉnh sửa file ceph-ansilbe/groups_vars/all.yml với các disk nếu cần
- Thực hiện add Node vào Cluster 
```sh
cd ceph-ansible
ansible-playbook ceph-ansible/infrastructure-playbooks/add-osd.yml -i ceph-ansible/inventory
```
### 2.3 Xóa OSD khởi Cluster

Xóa OSD khởi Cluster như sau:
```sh
ansible-playbook ceph-ansible/infrastructure-playbooks/shrink-osd.yml -e osd_to_kill=0,2,6
```
Trong đó:
 - 0,2,6: là ID của OSD tương ứng
 
### 2.4 Deploy OSD sử dụng backend là Bluestore
#### 2.4.1 Khai báo trong `group_vars`

- Mặc định đã sử dụng `Bluestore` tuy nhiên có thể chỉnh sửa file `ceph-ansible/groups_vars/all.yml` như sau:

```sh
## OSD options
osd_objectstore: bluestore
devices:
  - /dev/sda
  - /dev/sdb
  - /dev/sdc
dedicated_devices:
  - /dev/sdd
  - /dev/sde
  - /dev/sdf
bluestore_wal_devices:
  - /dev/sdg
  - /dev/sdh
  - /dev/sdi
```
- Hoặc khai báo như sau
```sh
## OSD options
osd_objectstore: bluestore
devices:
  - /dev/sda
  - /dev/sdb
  - /dev/sdc
dedicated_devices:
  - /dev/sdd
bluestore_wal_devices:
  - /dev/sde
```
Disk cho `block.db` và `block.wal` sẽ được chia đều trên 3 ổ `sdd` và `sde` cho 3 OSD
- Hoặc khai báo như sau
```sh
## OSD options
osd_objectstore: bluestore
devices:
  - /dev/sda
  - /dev/sdb
  - /dev/sdc
dedicated_devices:
  - /dev/sdd
  - /dev/sdd
  - /dev/sdd
bluestore_wal_devices:
  - /dev/sde
  - /dev/sde
  - /dev/sde
```
- Hoặc Chỉnh sửa file `ceph-ansible/roles/ceph-osd/defaults/main.yml` như sau:
```sh
# Khai báo OSD
devices:
  - /dev/sdb
  - /dev/sdc
  
# Khai báo block.db
dedicated_devices:
  - /dev/sdx
  - /dev/sdy
  
# Khai báo block.wal
bluestore_wal_devices:
  - /dev/nvme0n1
  - /dev/nvme0n2
```
### 2.5 Deploy OSD sử dụng backend là Filestore

- Mặc định đã sử dụng `Bluestore` tuy nhiên có thể chỉnh sửa file `ceph-ansible/groups_vars/all.yml` như sau:
```sh
## OSD options
osd_objectstore: filestore
lvm_volumes:
  - data: /dev/sdb
    journal: /dev/sdd1
  - data: /dev/sdc
    journal: /dev/sdd2
```

### 2.6 Thêm các tùy chọn khác

- Muốn tự động discovery các disk trong Node làm OSD chỉnh sửa file `ceph-ansible/groups_vars/all.yml` như sau:
```sh
# Mặc đinh là False
osd_auto_discovery: True
```
- Chỉnh sửa `bluestore_min_alloc_size` trong file `group_vars/all.yml` như sau:
```sh
ceph_conf_overrides:
  osd:
    bluestore_min_alloc_size: 4096
```
## Tài liệu tham khảo 
- https://github.com/ceph/ceph-ansible.git
- https://docs.ceph.com/ceph-ansible/master/
- https://docs.ceph.com/ceph-ansible/master/osds/scenarios.html
- https://programmer.group/deploying-docker-based-ceph-cluster-using-ceph-ansible.html
